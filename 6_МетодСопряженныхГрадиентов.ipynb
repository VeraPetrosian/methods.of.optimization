{"cells":[{"cell_type":"markdown","metadata":{"id":"28NxW9PWFeVr"},"source":["## Домашнее задание 6, Метод сопряженных градиентов\n"]},{"cell_type":"markdown","metadata":{"id":"MdRrBrQPXAGt"},"source":["### Deadline - 25.10.2024    23:59"]},{"cell_type":"markdown","metadata":{"id":"4hnwBapvFu9t"},"source":["## Основная часть (всего 5 баллов) "]},{"cell_type":"markdown","metadata":{"id":"KNAdB2e0vkNs"},"source":["Рассмотрим задачу минимизации следующей функции:\n","\n","$$\n","\\min_{x \\in \\mathbb{R}^n} \\left[ \\frac{1}{2} x^\\top A x - b^\\top x \\right]\n","$$\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CiXV9W7avkNs"},"source":["__Задача 1. (всего 2 балла)__ Реализуйте метод сопряженных градиентов и запустите на квадратичной функции.\n"]},{"cell_type":"markdown","metadata":{"id":"40X6p3Sdxqid"},"source":["**Псевдокод алгоритма**\n","\n","\n","_Инициализация:_ стартовая точка $x^0\\in \\mathbb{R}^d$, $r_0 = Ax_0 - b$, $p_0 = - r_0$, количество итераций $K$\n","\n","_k-ая итерация:_\n","\n","1. Обновляем параметр $\\alpha$, иными словами минимизируем фукнцию $f(x^k - \\alpha p_k)$ вдоль $p_k$\n","    $$\\alpha_k = -\\frac{r_k^T p_k}{p_k^T A p_k}$$\n","2. Делаем шаг\n","    $$x^{k+1} = x^k + \\alpha_k p_k$$\n","3. \n","    $$r_{k+1} = Ax^{k+1} - b$$\n","4. Находим коэффициент\n","    $$\\beta_{k+1} = \\frac{r_{k+1}^T A p_k}{p_k^T A p_k}$$\n","5. Находим новый сопряженный вектор\n","    $$p_{k+1} = - r_{k+1} + \\beta_{k+1} p_k$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"W_EdPSKGxrVg"},"source":["Для вашего удобства при реализации можете воспользоваться предложенным ниже кодом. После чего для проверки правильности загрузите функцию в [контест](https://contest.yandex.ru/contest/66540/enter/)\n","\n","Постройте графики сходимости. Код построения также предложен ниже."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"XTV4gP2cvkNt"},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","\n","RNG = np.random.default_rng(seed=0)\n","n = 50\n","sigma = 0\n","A = RNG.standard_normal((n, n))\n","A = A.T@A\n","\n","x_star = RNG.standard_normal((n,))\n","\n","b = A @ x_star + sigma * RNG.standard_normal((n,))\n","A, b = A.astype(np.float32), b.astype(np.float32)\n","\n","\n","x_0 = np.ones_like(x_star)\n","\n","def f(x, A, b):\n","    return 1/2 * x.T @ A @ x - b.T @ x\n","\n","def grad(x, A, b):\n","    # Ваше решение: реализуйте функцию расчета градиента\n","    pass\n","\n","def conjugate_grad_method(f = f, grad_f = grad, A = A, b = b,\n","                           x_0 = x_0, x_star = x_star, n_iter = None):\n","    '''\n","        f - целевая функция\n","        grad_f - градиент целевой функции\n","        A, b - соответсвующие параметры функции\n","        x_0 - стартовая точка\n","        x_star - точное решение\n","        n_iter - количество итераций (по умолчанию len(x_0))\n","\n","        Функция возвращает словать, хранящий точки функции на каждой из итерации\n","    '''\n","    if n_iter is None:\n","        n_iter = len(x_0)\n","    x = x_0\n","    r = grad_f(x_0, A, b)\n","    p = -grad_f(x_0, A, b)\n","    f_star = f(x_star, A, b)\n","\n","    trajectory = {}\n","    trajectory[\"f_gap\"] = np.zeros(shape=n_iter + 1)\n","    trajectory[\"x_gap\"] = np.zeros(shape=n_iter + 1)\n","    trajectory[\"f_gap\"][0] = np.abs(f(x, A, b) - f_star)\n","    trajectory[\"x_gap\"][0] = np.linalg.norm(x - x_star)\n","\n","    for i in range(n_iter):\n","        # Ваше решение\n","\n","        trajectory[\"f_gap\"][i + 1] = np.abs(f(x, A, b) - f_star)\n","        trajectory[\"x_gap\"][i + 1] = np.linalg.norm(x - x_star)\n","    return trajectory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDWLEIsPvkNt"},"outputs":[],"source":["metrics_cg = conjugate_grad_method(n_iter= 2*n)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngBQvlWCvkNu"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","plt.suptitle(f\"Random linear system of size {n}\")\n","ax1.set_xlabel(\"Iterations\")\n","ax1.set_ylabel(f\"$|f(x_k) - f(x_*)|$\")\n","ax1.semilogy(metrics_cg[\"f_gap\"])\n","ax1.grid(linestyle=\":\")\n","\n","ax2.set_xlabel(\"Iterations\")\n","ax2.set_ylabel(f\"$\\|x_k - x_*\\|$\")\n","ax2.semilogy(metrics_cg[\"x_gap\"], label=\"CG\")\n","ax2.legend()\n","ax2.grid(linestyle=\":\")\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lPl-dO9mvkNu"},"source":["__Задача 2. (всего 3 балла)__ Рассмотрим следующую функцию:\n","$$f(x) = x_1^4 - 2 x_1^2 x_2 + x_1^2 + x_2^2 - 2x_1$$\n","\n","Данная функция имеет минимум в точке $(x_1, x_2) = (1, 1)$.\n","\n","\n","__а\\). (1 балл)__\n","Реализуйте обобщение метода сопряженных градиентов Флетчера -- Ривса.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"r18otqmQ0YX0"},"source":["**Псевдокод алгоритма**\n","\n","\n","_Инициализация:_ стартовая точка $x^0\\in\\mathbb{R}^d$, $p_0 = - \\nabla f(x_0)$, количество итераций $K$\n","\n","_k-ая итерация:_\n","\n","1. Найдите $\\alpha_k$, используя линейный поиск\n","2. $x^{k+1} = x^k + \\alpha_k p_k$\n","3. $\\beta_{k+1} = \\frac{\\langle \\nabla f(x^{k+1}) , \\nabla f(x^{k+1}) \\rangle}{\\langle \\nabla f(x^k) , \\nabla f(x^k) \\rangle}$\n","4. $p_{k+1} = - \\nabla f(x^{k+1}) + \\beta_{k+1} p_k$"]},{"cell_type":"markdown","metadata":{"id":"IiLbByxE0UrT"},"source":["Для вашего удобства при реализации можете воспользоваться предложенным ниже кодом. После чего для проверки правильности загрузите функцию в [контест](https://contest.yandex.ru/contest/66540/enter/)\n","\n","Постройте графики сходимости. Код построения также предложен ниже."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8esL903vkNv"},"outputs":[],"source":["from scipy.optimize import minimize_scalar\n","import numpy as np\n","\n","\n","n = 2\n","x_0 = RNG.standard_normal((n,))\n","x_star = np.array([1.0, 1.0])\n","\n","def f(x):\n","    return x[0]**4 - 2*x[0]**2*x[1] + x[0]**2 + x[1]**2 - 2*x[0] + 1\n","\n","def grad(x):\n","    # Ваше решение: реализуйте функцию расчета градиента\n","    pass\n","\n","def fletcher_reeves_cg_method(f = f, grad_f = grad, x_0 = x_0, \n","                              x_star = x_star, n_iter = None):\n","    '''\n","        f - целевая функция\n","        grad_f - градиент целевой функции\n","        x_0 - стартовая точка\n","        x_star - точное решение\n","        n_iter - количество итераций (по умолчанию len(x_0))\n","\n","        Функция возвращает словать, хранящий точки функции на каждой из итерации\n","    '''\n","    if n_iter is None:\n","        n_iter = len(x_0)\n","    x = x_0\n","    x_old = x_0\n","    p = -grad_f(x_0)\n","    f_star = f(x_star)\n","\n","    trajectory = {}\n","    trajectory[\"f_gap\"] = np.zeros(shape=n_iter + 1)\n","    trajectory[\"x_gap\"] = np.zeros(shape=n_iter + 1)\n","    trajectory[\"f_gap\"][0] = np.abs(f(x) - f_star)\n","    trajectory[\"x_gap\"][0] = np.linalg.norm(x - x_star)\n","\n","    for i in range(n_iter):\n","        # Ваше решение\n","\n","        trajectory[\"f_gap\"][i + 1] = np.abs(f(x) - f_star)\n","        trajectory[\"x_gap\"][i + 1] = np.linalg.norm(x - x_star)\n","    return trajectory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNGHfXdYvkNv"},"outputs":[],"source":["metrics_fr = fletcher_reeves_cg_method(n_iter=30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHHs4emCvkNv"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","plt.suptitle(f\"Rosenbrock function\")\n","ax1.set_xlabel(\"Iterations\")\n","ax1.set_ylabel(f\"$|f(x_k) - f(x_*)|$\")\n","ax1.semilogy(metrics_fr[\"f_gap\"])\n","ax1.grid(linestyle=\":\")\n","\n","ax2.set_xlabel(\"Iterations\")\n","ax2.set_ylabel(f\"$\\|x_k - x_*\\|$\")\n","ax2.semilogy(metrics_fr[\"x_gap\"], label=\"CG FR\")\n","ax2.legend()\n","ax2.grid(linestyle=\":\")\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hiq4pg_vvkNv"},"source":["__б\\). (1 балл)__\n","Реализуйте обобщение метода сопряженных градиентов Полака -- Рибьера.\n"]},{"cell_type":"markdown","metadata":{"id":"x51VHtWu0ta5"},"source":["**Псевдокод алгоритма**\n","\n","_Инициализация:_ стартовая точка $x^0\\in\\mathbb{R}^d$, $p_0 = - \\nabla f(x_0)$, количество итераций $K$\n","\n","_k-ая итерация:_\n","\n","1. Найдите $\\alpha_k$, используя линейный поиск\n","2. $x^{k+1} = x^k + \\alpha_k p_k$\n","3. $\\beta_{k+1} = \\frac{\\langle \\nabla f(x^{k+1}) , \\nabla f(x^{k+1}) - \\nabla f(x^{k}) \\rangle}{\\langle \\nabla f(x^k) , \\nabla f(x^k) \\rangle}$\n","4. $p_{k+1} = - \\nabla f(x^{k+1}) + \\beta_{k+1} p_k$\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1U7Agb_s0uoo"},"source":["Для вашего удобства при реализации можете воспользоваться предложенным ниже кодом. После чего для проверки правильности загрузите функцию в [контест](https://contest.yandex.ru/contest/66540/enter/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ocj2tr5NvkNw"},"outputs":[],"source":["from scipy.optimize import minimize_scalar\n","\n","n = 2\n","x_0 = RNG.standard_normal((n,))\n","x_star = np.array([1.0, 1.0])\n","\n","def f(x):\n","    return x[0]**4 - 2*x[0]**2*x[1] + x[0]**2 + x[1]**2 - 2*x[0]\n","\n","def grad_f(x):\n","    # Ваше решение: реализуйте функцию расчета градиента\n","    pass\n","\n","def polak_ribiere_cg_method(f = f, grad_f = grad, x_0 = x_0, \n","                              x_star = x_star, n_iter = None):\n","    '''\n","        f - целевая функция\n","        grad_f - градиент целевой функции\n","        x_0 - стартовая точка\n","        x_star - точное решение\n","        n_iter - количество итераций (по умолчанию len(x_0))\n","\n","        Функция возвращает словать, хранящий точки функции на каждой из итерации\n","    '''\n","    if n_iter is None:\n","        n_iter = len(x_0)\n","    x = x_0\n","    x_old = x_0\n","    p = -grad_f(x_0)\n","    f_star = f(x_star)\n","\n","    trajectory = {}\n","    trajectory[\"f_gap\"] = np.zeros(shape=n_iter + 1)\n","    trajectory[\"x_gap\"] = np.zeros(shape=n_iter + 1)\n","    trajectory[\"f_gap\"][0] = np.abs(f(x) - f_star)\n","    trajectory[\"x_gap\"][0] = np.linalg.norm(x - x_star)\n","\n","    for i in range(n_iter):\n","        # Ваше решение\n","\n","        trajectory[\"f_gap\"][i + 1] = np.abs(f(x) - f_star)\n","        trajectory[\"x_gap\"][i + 1] = np.linalg.norm(x - x_star)\n","    return trajectory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0r1C9rovkNw"},"outputs":[],"source":["metrics_pr = polak_ribiere_cg_method(n_iter=30)"]},{"cell_type":"markdown","metadata":{"id":"9Ldaf4xVvkNw"},"source":["__в\\). (1 балл)__\n","Постройте кривые сходимости метода Флетчера -- Ривса и метода Полака -- Рибьера на одном графике.\n","\n","Сделайте вывод о сходимости методов. Какой из них сходится быстрее на рассматриваемой функции.\n","\n","Для вашего удобства можете воспользоваться предложенным ниже кодом построения графиков."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDyFVN05vkNx"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","plt.suptitle(f\"Rosenbrock function\")\n","ax1.set_xlabel(\"Iterations\")\n","ax1.set_ylabel(f\"$|f(x_k) - f(x_*)|$\")\n","ax1.semilogy(metrics_fr[\"f_gap\"], label=\"CG FR\")\n","ax1.semilogy(metrics_pr[\"f_gap\"], label=\"CG PR\")\n","ax1.grid(linestyle=\":\")\n","\n","ax2.set_xlabel(\"Iterations\")\n","ax2.set_ylabel(f\"$\\|x_k - x_*\\|$\")\n","ax2.semilogy(metrics_fr[\"x_gap\"], label=\"CG FR\")\n","ax2.semilogy(metrics_pr[\"x_gap\"], label=\"CG PR\")\n","ax2.legend()\n","ax2.grid(linestyle=\":\")\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"K6yvUpoqRmFa"},"source":["## Дополнительная часть (Всего 5 баллов)"]},{"cell_type":"markdown","metadata":{},"source":["__Задача 1. (всего 3 балла)__  Снова рассмотрим квадратичную задачу :\n","$$\\min_{x \\in \\mathbb{R}^d} \\left[\\tfrac{1}{2} x^T A x - b x \\right]$$\n","с положительно определенной симметричной матрицей $A \\in \\mathbb{R}^{d \\times d}$ и некоторым вектором $b \\in \\mathbb{R}^d$.\n","\n","Исследуем особенности метода сопряженных градиентов, за которые он и получил популярность, как алгоритм численного решения системы линейных уравнений.\n","Для этого нам нужно научиться генерировать матрицу $A$ с возможнностью задавать ее спектр (собственные значения). В задании про градиентный спуск уже просили сделать это. Мы советуем использовать следующий подход, основанный на разложении $A = Q D Q^T$, где матрица $D$ - диагональная, образованная из собственных значений, а $Q$ - ортогональная (ее можно сгенерировать с помощью $QR$-разложения случайной матрицы).\n","\n","Пусть у нас имеется квадратичная задача, у которой матрица $A \\in \\mathbb{R}^{d \\times d}$ имеет кластеризованные собственные значения, это означает, что существует некоторое число кластеров $k \\leq d$ и значения $\\tilde \\lambda_1 < \\ldots < \\tilde \\lambda_k$, что для любого $\\lambda_i$ собственного значения матрицы $A$ существует $j \\leq k$ такой, что $\\lambda_i \\in [(1 - p) \\tilde \\lambda_j; (1 + p) \\tilde \\lambda_j]$, где $p < 1$.\n","\n","Далее нужно будет генерировать кластеризованные собственные значения, а потом и матрицу $A$. Старайтесь при генерации спектра удостоверится, что все значения в нем разные. В качесве критерия сходимости используйте $\\frac{\\| x^k - x^* \\|^2_A} {\\| x^0 - x^* \\|^2_A}$, где $k$ - номер итерации, а $\\| x \\|^2_A = \\langle x, Ax \\rangle$.\n","\n","Протестируем работу метода сопряженных градиентов для различных вариантов кластеризации собственных значений:"]},{"cell_type":"markdown","metadata":{},"source":["\n","__а\\). (0.5 балла)__ Пусть $d = 100$, $k = 2$, $p = 0,05$, $\\tilde \\lambda_1 = 1$, в кластерах для $\\tilde \\lambda_1$ и $\\tilde \\lambda_2$ находится по 50 собственных значений. Варьируйте значение $\\tilde \\lambda_2$ от $10$ до $10^5$ (5 различных значений достаточно). На одном графике отобразите значения критерия сходимости от номера итерации для каждого значения $\\tilde \\lambda_2$."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Ваше решение\n","\n","\n","# Также можете воспользоваться предложенным вариантом реализации кода генерации матрицы\n","from scipy.stats import ortho_group\n","import numpy as np\n","\n","cluster_val_quantity = 50\n","clusters = [[cluster_val_quantity, i] for i in 10**np.linspace(1, 5, 5)]\n","\n","def A_gen(d: int, clusters: list, p: float = 0.05) -> np.ndarray:\n","    '''\n","    d - размерность матрицы\n","    clusters - list, где каждый элемент есть [количество чисел в кластере, среднее значение в кластере]\n","    p - разброс значений в кластере\n","    '''\n","    eign_vals = []\n","    q_sum = 0\n","    for quantity, val in clusters:\n","        min_val = (1 - p)*val\n","        max_val = (1 + p)*val\n","        eign_vals.extend(min_val + np.random.random(quantity)*(max_val - min_val))\n","        q_sum += quantity\n","    if (q_sum != d):\n","        raise ValueError()\n","    np.random.shuffle(eign_vals)\n","    S = np.diag(eign_vals)\n","    U = ortho_group.rvs(d)\n","    return U.T @ S @ U"]},{"cell_type":"markdown","metadata":{},"source":["\n","__б\\). (0.5 балла)__ Пусть $d = 100$, $k = 2$, $p = 0,05$, $\\tilde \\lambda_1 = 1$, $\\tilde \\lambda_2 = 1000$. Варьируйте количество собственных значений в каждом из кластеров от $1$ до $99$ (5 различных значений достаточно). На одном графике отобразите значения критерия сходимости от номера итерации для каждого значения размера кластера для $\\tilde \\lambda_1$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ваше решение"]},{"cell_type":"markdown","metadata":{},"source":["__в\\). (0.5 балла)__ Пусть $d = 100$, $p = 0,05$, $\\tilde \\lambda_1 = 1$, $\\tilde \\lambda_k = 1000$. Варьируйте количество кластеров $k$ от 2 до 100 (5 различных значений достаточно, включите 100 - соотвествует равномерному распределению собственных значений). На одном графике отобразите значения критерия сходимости от номера итерации для каждого значения  $k$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ваше решение"]},{"cell_type":"markdown","metadata":{},"source":["Опишите полученные результаты. Как Вы думаете, почему наблюдаются такие различия в сходимостях?"]},{"cell_type":"markdown","metadata":{},"source":["__Ваше решение__"]},{"cell_type":"markdown","metadata":{},"source":["__г\\). (1.5 балла)__ Добавьте возможность рестарта алгоритма. Для этого нужно добавить возможность задавать $\\beta_k = 0$ раз в несколько шагов. Общий вид алгоритма будет следующим:\n","\n","**Псевдокод алгоритма**\n","\n","\n","_Инициализация:_ стартовая точка $x^0\\in \\mathbb{R}^d$, $r_0 = Ax_0 - b$, $p_0 = - r_0$, количество итераций $K$, количество шагов до рестарта $P_r$\n","\n","_k-ая итерация:_\n","\n","1. Обновляем параметр $\\alpha$, иными словами минимизируем фукнцию $f(x^k - \\alpha p_k)$ вдоль $p_k$\n","    $$\\alpha_k = -\\frac{r_k^T p_k}{p_k^T A p_k}$$\n","2. Делаем шаг\n","    $$x^{k+1} = x^k + \\alpha_k p_k$$\n","3. \n","    $$r_{k+1} = Ax^{k+1} - b$$\n","4. Найдем множитель $\\xi$ при $\\beta$ из множества $\\{0,1\\}$. \n","    $$\\text{Если }k \\text{ кратно }P_r, \\xi = 0, \\text{иначе } \\xi = 1$$\n","5. Находим коэффициент\n","    $$\\beta_{k+1} = \\frac{r_{k+1}^T A p_k}{p_k^T A p_k} \\cdot \\xi$$\n","6. Находим новый сопряженный вектор\n","    $$p_{k+1} = - r_{k+1} + \\beta_{k+1} p_k$$"]},{"cell_type":"markdown","metadata":{},"source":["Запустите новый алгоритм с рестартами при условиях из пунктов а, б и в, но при одном значении вариации матрицы. Для пункта в задайте $k = 100$. \n","\n","Для каждого из пунктов добавьте на график результат алгоритма с рестартами и без рестартов."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ваше решение, пункт а"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ваше решение, пункт б"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ваше решение, пункт в"]},{"cell_type":"markdown","metadata":{},"source":["Сравните полученные результаты. Как думаете, почему наблюдается такой эффект?"]},{"cell_type":"markdown","metadata":{},"source":["__Ваше решение__"]},{"cell_type":"markdown","metadata":{"id":"zcmG6DtFvkNx"},"source":["__Задача 2. (всего 2 балла)__ Рассмотрим следующую функцию, которая возникает в задачах машинного обучения (функция потерь логистической регрессии с $l_2$ регуляризацией). :\n","\n","$$\n","\\min_w \\left[\\frac1m \\sum_{i=1}^m \\log (1 + \\exp(- y_i \\langle x_i, w \\rangle)) + \\frac12 \\|w\\|_2^2\\right]\n","$$\n","\n","\n","__а\\). (1 балл)__\n","Реализуйте следующие методы для поиска минимума данной функции:\n","* метод Флетчера -- Ривса\n","* метод Полака -- Рибьера\n","* градиентный спуск с постоянным шагом\n","* градиентный спуск с линейным поиском\n","\n","Для вашего удобства при реализации можете воспользоваться предложенным ниже кодом.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAanLdBNWR_F","outputId":"66b911e0-a6be-4547-b943-aecc6aa93668"},"outputs":[],"source":["import numpy as np\n","import sklearn.datasets as skldata\n","\n","\n","n = 300\n","m = 1000\n","\n","X, y = skldata.make_classification(n_classes=2, n_features=n, n_samples=m,\n","                                   n_informative=n//3, random_state=0)\n","X = np.array(X)\n","y = np.array(y)\n","\n","def f(w):\n","    return np.mean(np.logaddexp(np.zeros(X.shape[0]), -y * (X @ w))) + \\\n","        np.linalg.norm(w)**2 / 2\n","\n","def grad_f(x):\n","    # Ваше решение: реализуйте функцию расчета градиента\n","    pass\n","\n","\n","RNG = np.random.default_rng(seed=0)\n","sigma = 0\n","x0 = RNG.standard_normal((n,))\n","print(f\"Initial function value = {f(x0)}\")\n","print(f\"Initial gradient norm = {np.linalg.norm(grad_f(x0))}\")\n","# Ваше решение"]},{"cell_type":"markdown","metadata":{"id":"WulCnka5W6ZF"},"source":["\n","__б\\). (1 балл)__\n","Постройте на одном графике кривые сходимости методов. Сделайте вывод о том, какой метод сходится быстрее на рассматриваемой функции.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZ_KvVUJWSdG"},"outputs":[],"source":["# Ваше решение"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"hw_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
